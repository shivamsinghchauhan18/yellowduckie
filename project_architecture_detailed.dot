// Comprehensive Duckietown Safe Navigation Project Architecture
// Advanced Safety & Navigation System with Predictive Capabilities
// Author: Shivam Singh
// Render with: dot -Tpng project_architecture_detailed.dot -o project_architecture_detailed.png
// Or: neato -Tsvg project_architecture_detailed.dot -o project_architecture_detailed.svg

digraph DuckietownSafeNavigation {
    // Graph properties
    rankdir=TB;
    splines=true;
    overlap=false;
    concentrate=true;
    compound=true;
    fontname="Arial";
    fontsize=12;
    
    // Node styles
    node [fontname="Arial", fontsize=10, style=filled];
    edge [fontname="Arial", fontsize=8];
    
    // Color scheme
    subgraph cluster_legend {
        label="Legend";
        style=filled;
        color="#f0f0f0";
        fontsize=10;
        
        legend_sensor [label="Sensor Layer", shape=box, fillcolor="#e1f5fe", color="#0277bd"];
        legend_perception [label="Perception Layer", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        legend_safety [label="Safety Layer", shape=box, fillcolor="#ffebee", color="#c62828"];
        legend_decision [label="Decision Layer", shape=box, fillcolor="#e8f5e8", color="#2e7d32"];
        legend_control [label="Control Layer", shape=box, fillcolor="#fff3e0", color="#ef6c00"];
        legend_monitoring [label="Monitoring Layer", shape=box, fillcolor="#fafafa", color="#424242"];
        legend_communication [label="Communication", shape=ellipse, fillcolor="#f1f8e9", color="#558b2f"];
        legend_data [label="Data Flow", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
    }
    
    // ========== SENSOR LAYER ==========
    subgraph cluster_sensors {
        label="ğŸ” SENSOR LAYER";
        style=filled;
        color="#e1f5fe";
        fontcolor="#0277bd";
        fontsize=14;
        
        // Hardware sensors
        camera_node [label="Camera Node\n(camera_driver_node.py)\nğŸ“· Image Capture\nğŸ¥ Video Stream", shape=box, fillcolor="#e1f5fe", color="#0277bd"];
        camera_mock [label="Camera Mock\n(camera_mock_node.py)\nğŸ­ Simulation Mode\nğŸ“¸ Test Images", shape=box, fillcolor="#e1f5fe", color="#0277bd"];
        imu_sensors [label="IMU Sensors\nâš¡ Accelerometer\nğŸ§­ Gyroscope\nğŸ§² Magnetometer", shape=box, fillcolor="#e1f5fe", color="#0277bd"];
        wheel_encoders [label="Wheel Encoders\nâš™ï¸ Speed Measurement\nğŸ“ Distance Tracking", shape=box, fillcolor="#e1f5fe", color="#0277bd"];
        
        // Sensor data topics
        image_compressed [label="image/compressed\nğŸ“Š Compressed Images", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        camera_info [label="camera_info\nğŸ“‹ Camera Parameters", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        imu_data [label="imu/data\nğŸ“ˆ Motion Data", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        encoder_data [label="encoder_ticks\nğŸ”¢ Wheel Rotation", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
    }
    
    // ========== PERCEPTION LAYER ==========
    subgraph cluster_perception {
        label="ğŸ‘ï¸ PERCEPTION LAYER";
        style=filled;
        color="#f3e5f5";
        fontcolor="#7b1fa2";
        fontsize=14;
        
        // Core perception
        line_detector [label="Line Detector\n(line_detector_node.py)\nğŸ›£ï¸ Lane Detection\nğŸ“ Segment Extraction", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        ground_projection [label="Ground Projection\n(ground_projection_node.py)\nğŸŒ 3D Mapping\nğŸ“ Coordinate Transform", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        lane_filter [label="Lane Filter\n(lane_filter_node.py)\nğŸ¯ Position Estimation\nğŸ“Š Pose Calculation", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        
        // Object detection
        object_detection [label="Enhanced Object Detection\n(enhanced_object_detection_node.py)\nğŸ¤– Neural Network\nğŸ¯ Multi-class Detection", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        vehicle_detection [label="Vehicle Detection\n(vehicle_detection_node.py)\nğŸš— Vehicle Recognition\nğŸ“ Position Tracking", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        apriltag_detector [label="AprilTag Detector\n(apriltag_detector_node.py)\nğŸ·ï¸ Sign Recognition\nğŸ“ Landmark Detection", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        
        // Advanced perception (NEW)
        predictive_perception [label="ğŸ†• Predictive Perception Manager\n(predictive_perception_manager_node.py)\nğŸ”® Trajectory Prediction\nğŸ“Š Multi-Object Tracking\nğŸ¯ Kalman Filtering", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        scene_understanding [label="ğŸ†• Scene Understanding Module\n(scene_understanding_module_node.py)\nğŸ§  Context Analysis\nğŸŒ Environment Assessment\nğŸ“‹ Scenario Classification", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        sensor_fusion [label="ğŸ†• Perception Data Fusion\n(perception_data_fusion_node.py)\nğŸ”— Multi-Modal Fusion\nğŸ“Š Confidence Estimation\nâš–ï¸ Data Arbitration", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        
        // Image processing pipeline
        anti_instagram [label="Anti-Instagram\n(anti_instagram_node.py)\nğŸ¨ Color Correction\nğŸ’¡ Lighting Adaptation", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        image_processing [label="Image Processing\nğŸ“¸ Rectification\nğŸ”§ Preprocessing", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        
        // Perception data
        segment_list [label="segment_list\nğŸ“ Lane Segments", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        lane_pose [label="lane_pose\nğŸ“ Vehicle Position", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        object_detections [label="object_detections\nğŸ¯ Detected Objects", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        predicted_trajectories [label="predicted_trajectories\nğŸ”® Future Paths", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        scene_analysis [label="scene_analysis\nğŸ§  Scene Context", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
    }
    
    // ========== SAFETY LAYER (NEW) ==========
    subgraph cluster_safety {
        label="ğŸ›¡ï¸ ADVANCED SAFETY LAYER";
        style=filled;
        color="#ffebee";
        fontcolor="#c62828";
        fontsize=14;
        
        // Core safety systems
        emergency_stop [label="ğŸ†• Emergency Stop System\n(emergency_stop_system_node.py)\nğŸš¨ Immediate Stop\nâš¡ Hardware Override\nâ±ï¸ <100ms Response", shape=box, fillcolor="#ffebee", color="#c62828"];
        collision_detection [label="ğŸ†• Collision Detection Manager\n(collision_detection_manager_node.py)\nğŸ’¥ Risk Assessment\nğŸ“Š Multi-Layer Detection\nâš ï¸ Threat Classification", shape=box, fillcolor="#ffebee", color="#c62828"];
        safety_fusion [label="ğŸ†• Safety Fusion Manager\n(safety_fusion_manager_node.py)\nğŸ”— Safety Coordination\nâš–ï¸ Decision Arbitration\nğŸ“Š Health Monitoring", shape=box, fillcolor="#ffebee", color="#c62828"];
        safety_arbiter [label="ğŸ†• Safety Command Arbiter\n(safety_command_arbiter_node.py)\nğŸ›ï¸ Command Override\nâš–ï¸ Priority Management\nğŸ›¡ï¸ Safety Enforcement", shape=box, fillcolor="#ffebee", color="#c62828"];
        
        // Configuration and validation
        safety_config [label="ğŸ†• Safety Config Validator\n(safety_config_validator.py)\nâœ… Parameter Validation\nğŸ”§ Configuration Check\nğŸ“‹ Safety Standards", shape=box, fillcolor="#ffebee", color="#c62828"];
        dynamic_params [label="ğŸ†• Dynamic Parameter Manager\n(dynamic_parameter_manager.py)\nâš™ï¸ Runtime Tuning\nğŸ“Š Adaptive Parameters\nğŸ”„ Real-time Updates", shape=box, fillcolor="#ffebee", color="#c62828"];
        
        // Safety data
        collision_risk [label="collision_risk\nâš ï¸ Risk Levels", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        emergency_status [label="emergency_status\nğŸš¨ System State", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        safety_override [label="safety_override\nğŸ›¡ï¸ Safety Commands", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
    }
    
    // ========== DECISION LAYER ==========
    subgraph cluster_decision {
        label="ğŸ§  INTELLIGENT DECISION LAYER";
        style=filled;
        color="#e8f5e8";
        fontcolor="#2e7d32";
        fontsize=14;
        
        // Core control
        lane_controller [label="Lane Controller\n(lane_controller_node.py)\nğŸ›£ï¸ Lane Following\nğŸ¯ Path Tracking\nâš–ï¸ PID Control", shape=box, fillcolor="#e8f5e8", color="#2e7d32"];
        stop_line_filter [label="Stop Line Filter\n(stop_line_filter_node.py)\nğŸ›‘ Stop Detection\nğŸ“ Distance Calculation\nâš ï¸ Intersection Logic", shape=box, fillcolor="#e8f5e8", color="#2e7d32"];
        
        // Advanced decision making (NEW)
        adaptive_speed [label="ğŸ†• Adaptive Speed Controller\n(adaptive_speed_controller_node.py)\nğŸš€ Dynamic Speed\nğŸŒ¦ï¸ Environmental Adaptation\nğŸ“Š Multi-Factor Control", shape=box, fillcolor="#e8f5e8", color="#2e7d32"];
        lane_change_controller [label="ğŸ†• Lane Change Controller\nğŸ”„ Safe Lane Changes\nğŸ“Š Feasibility Analysis\nğŸš¦ Signal Coordination", shape=box, fillcolor="#e8f5e8", color="#2e7d32"];
        intelligent_navigation [label="ğŸ†• Intelligent Navigation Manager\nğŸ—ºï¸ Path Planning\nğŸ¯ Multi-Objective Optimization\nğŸš¦ Traffic Rule Compliance", shape=box, fillcolor="#e8f5e8", color="#2e7d32"];
        
        // Supporting modules
        acceleration_profile [label="ğŸ†• Acceleration Profile Manager\n(acceleration_profile_manager.py)\nğŸ“ˆ Smooth Profiles\nâš¡ Jerk Minimization\nğŸ¯ Comfort Optimization", shape=box, fillcolor="#e8f5e8", color="#2e7d32"];
        following_distance [label="ğŸ†• Following Distance Controller\n(following_distance_controller.py)\nğŸš— Vehicle Following\nğŸ“ Safe Distance\nâ±ï¸ Time-based Control", shape=box, fillcolor="#e8f5e8", color="#2e7d32"];
        environmental_analyzer [label="ğŸ†• Environmental Analyzer\n(environmental_analyzer.py)\nğŸŒ¦ï¸ Condition Assessment\nğŸ’¡ Visibility Analysis\nğŸ“Š Risk Evaluation", shape=box, fillcolor="#e8f5e8", color="#2e7d32"];
        
        // Decision data
        car_cmd [label="car_cmd\nğŸ›ï¸ Control Commands", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        speed_command [label="speed_command\nğŸš€ Speed Control", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        lane_change_request [label="lane_change_request\nğŸ”„ Maneuver Plans", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
    }
    
    // ========== CONTROL LAYER ==========
    subgraph cluster_control {
        label="ğŸ›ï¸ CONTROL & ACTUATION LAYER";
        style=filled;
        color="#fff3e0";
        fontcolor="#ef6c00";
        fontsize=14;
        
        // Actuation
        wheels_driver [label="Wheels Driver\n(wheels_driver_node.py)\nâš™ï¸ Motor Control\nğŸ“Š Encoder Feedback\nğŸ”§ Hardware Interface", shape=box, fillcolor="#fff3e0", color="#ef6c00"];
        
        // LED control
        led_emitter [label="LED Emitter\n(led_emitter_node.py)\nğŸ’¡ Light Control\nğŸ¨ Pattern Generation\nğŸ“¡ Signal Display", shape=box, fillcolor="#fff3e0", color="#ef6c00"];
        led_pattern_switch [label="LED Pattern Switch\n(led_pattern_switch_node.py)\nğŸ”„ Pattern Selection\nğŸ­ State-based Switching\nğŸš¦ Traffic Signals", shape=box, fillcolor="#fff3e0", color="#ef6c00"];
        led_joy_mapper [label="LED Joy Mapper\n(led_joy_mapper_node.py)\nğŸ® Manual Control\nğŸ¯ Joystick Mapping\nğŸ¨ Interactive Patterns", shape=box, fillcolor="#fff3e0", color="#ef6c00"];
        
        // Control data
        wheels_cmd [label="wheels_cmd\nâš™ï¸ Wheel Commands", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        wheels_cmd_executed [label="wheels_cmd_executed\nâœ… Execution Feedback", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        led_pattern [label="led_pattern\nğŸ’¡ Light Patterns", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
    }
    
    // ========== MONITORING LAYER (NEW) ==========
    subgraph cluster_monitoring {
        label="ğŸ“Š SYSTEM MONITORING & DIAGNOSTICS";
        style=filled;
        color="#fafafa";
        fontcolor="#424242";
        fontsize=14;
        
        // Monitoring systems
        performance_monitor [label="ğŸ†• Performance Monitor\n(performance_monitor_node.py)\nğŸ“ˆ System Metrics\nâš¡ Real-time Analysis\nğŸ¯ Optimization Hints", shape=box, fillcolor="#fafafa", color="#424242"];
        system_health [label="ğŸ†• System Health Monitor\nğŸ¥ Component Status\nâš ï¸ Failure Detection\nğŸ”§ Diagnostic Reports", shape=box, fillcolor="#fafafa", color="#424242"];
        data_logger [label="ğŸ†• Data Logger\nğŸ“ Event Recording\nğŸ’¾ Data Storage\nğŸ“Š Analysis Support", shape=box, fillcolor="#fafafa", color="#424242"];
        
        // Monitoring data
        system_metrics [label="system_metrics\nğŸ“Š Performance Data", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        diagnostic_info [label="diagnostic_info\nğŸ” System Status", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
    }
    
    // ========== STATE MANAGEMENT ==========
    subgraph cluster_fsm {
        label="ğŸ”„ FINITE STATE MACHINE";
        style=filled;
        color="#f1f8e9";
        fontcolor="#558b2f";
        fontsize=14;
        
        fsm_node [label="FSM Node\n(fsm_node.py)\nğŸ”„ State Management\nğŸ­ Behavior Switching\nğŸ“‹ Mode Control", shape=box, fillcolor="#f1f8e9", color="#558b2f"];
        fsm_state [label="fsm_state\nğŸ­ Current Mode", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
    }
    
    // ========== COMMUNICATION & COORDINATION ==========
    subgraph cluster_communication {
        label="ğŸ“¡ COMMUNICATION & COORDINATION";
        style=filled;
        color="#f1f8e9";
        fontcolor="#558b2f";
        fontsize=14;
        
        v2v_communication [label="ğŸ†• V2V Communication\nğŸ“¡ Vehicle-to-Vehicle\nğŸ¤ Coordination Protocol\nâš ï¸ Emergency Alerts", shape=ellipse, fillcolor="#f1f8e9", color="#558b2f"];
        intersection_coordinator [label="ğŸ†• Intersection Coordinator\nğŸš¦ Traffic Management\nğŸ¯ Right-of-Way Logic\nâš–ï¸ Conflict Resolution", shape=ellipse, fillcolor="#f1f8e9", color="#558b2f"];
        
        // Communication data
        v2v_messages [label="v2v_messages\nğŸ“¨ Inter-Vehicle Data", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
        coordination_data [label="coordination_data\nğŸ¤ Shared Information", shape=diamond, fillcolor="#fff8e1", color="#f57f17"];
    }
    
    // ========== VISUALIZATION & DEBUGGING ==========
    subgraph cluster_visualization {
        label="ğŸ“ˆ VISUALIZATION & DEBUGGING";
        style=filled;
        color="#f3e5f5";
        fontcolor="#7b1fa2";
        fontsize=14;
        
        line_segment_visualizer [label="Line Segment Visualizer\n(line_segment_visualizer_node.py)\nğŸ“Š Lane Visualization\nğŸ¨ Debug Display", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        lane_pose_visualizer [label="Lane Pose Visualizer\n(lane_pose_visualizer_node.py)\nğŸ“ Position Display\nğŸ¯ Tracking Visualization", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
        trajectory_visualizer [label="ğŸ†• Trajectory Visualizer\n(trajectory_visualizer.py)\nğŸ”® Path Prediction Display\nğŸ“ˆ Motion Visualization", shape=box, fillcolor="#f3e5f5", color="#7b1fa2"];
    }
    
    // ========== NEURAL NETWORK & AI ==========
    subgraph cluster_ai {
        label="ğŸ¤– NEURAL NETWORK & AI";
        style=filled;
        color="#e8eaf6";
        fontcolor="#3f51b5";
        fontsize=14;
        
        nn_model [label="Neural Network Model\n(model.py)\nğŸ§  Deep Learning\nğŸ¯ Object Classification\nâš¡ GPU Acceleration", shape=box, fillcolor="#e8eaf6", color="#3f51b5"];
        kalman_tracker [label="ğŸ†• Kalman Tracker\n(kalman_tracker.py)\nğŸ“Š State Estimation\nğŸ¯ Noise Filtering\nğŸ“ˆ Prediction Model", shape=box, fillcolor="#e8eaf6", color="#3f51b5"];
        multi_object_tracker [label="ğŸ†• Multi-Object Tracker\n(multi_object_tracker.py)\nğŸ¯ Multiple Targets\nğŸ”— Association Logic\nğŸ“Š Track Management", shape=box, fillcolor="#e8eaf6", color="#3f51b5"];
        motion_models [label="ğŸ†• Motion Models\n(motion_models.py)\nğŸš— Vehicle Dynamics\nğŸ“ˆ Kinematic Models\nğŸ”® Behavior Prediction", shape=box, fillcolor="#e8eaf6", color="#3f51b5"];
    }
    
    // ========== EXTERNAL INTERFACES ==========
    subgraph cluster_external {
        label="ğŸŒ EXTERNAL INTERFACES";
        style=dashed;
        color="#e0e0e0";
        fontcolor="#616161";
        fontsize=14;
        
        joystick_input [label="Joystick Input\nğŸ® Manual Control\nğŸ¯ Teleoperation", shape=box, fillcolor="#f5f5f5", color="#616161"];
        network_interface [label="Network Interface\nğŸŒ Remote Access\nğŸ“¡ Data Transmission", shape=box, fillcolor="#f5f5f5", color="#616161"];
        file_system [label="File System\nğŸ’¾ Configuration Files\nğŸ“Š Log Storage", shape=box, fillcolor="#f5f5f5", color="#616161"];
    }
    
    // ========== DATA FLOW CONNECTIONS ==========
    
    // Sensor to Perception
    camera_node -> image_compressed;
    camera_node -> camera_info;
    camera_mock -> image_compressed [style=dashed, label="simulation"];
    imu_sensors -> imu_data;
    wheel_encoders -> encoder_data;
    
    image_compressed -> line_detector;
    image_compressed -> object_detection;
    image_compressed -> vehicle_detection;
    image_compressed -> apriltag_detector;
    image_compressed -> anti_instagram;
    camera_info -> ground_projection;
    camera_info -> apriltag_detector;
    
    // Perception pipeline
    line_detector -> segment_list;
    segment_list -> ground_projection;
    ground_projection -> lane_filter;
    lane_filter -> lane_pose;
    
    object_detection -> object_detections;
    vehicle_detection -> object_detections;
    apriltag_detector -> object_detections;
    
    // Advanced perception
    object_detections -> predictive_perception;
    lane_pose -> predictive_perception;
    predictive_perception -> predicted_trajectories;
    
    object_detections -> scene_understanding;
    lane_pose -> scene_understanding;
    scene_understanding -> scene_analysis;
    
    object_detections -> sensor_fusion;
    predicted_trajectories -> sensor_fusion;
    scene_analysis -> sensor_fusion;
    
    // Safety system
    object_detections -> collision_detection;
    predicted_trajectories -> collision_detection;
    collision_detection -> collision_risk;
    
    collision_risk -> emergency_stop;
    emergency_stop -> emergency_status;
    emergency_stop -> safety_override;
    
    collision_risk -> safety_fusion;
    emergency_status -> safety_fusion;
    safety_fusion -> safety_arbiter;
    
    // Decision making
    lane_pose -> lane_controller;
    lane_pose -> stop_line_filter;
    segment_list -> stop_line_filter;
    
    lane_pose -> adaptive_speed;
    object_detections -> adaptive_speed;
    scene_analysis -> adaptive_speed;
    adaptive_speed -> speed_command;
    
    lane_controller -> car_cmd;
    adaptive_speed -> car_cmd;
    
    // Safety override
    car_cmd -> safety_arbiter;
    safety_override -> safety_arbiter;
    safety_arbiter -> wheels_cmd;
    
    // Control
    wheels_cmd -> wheels_driver;
    wheels_driver -> wheels_cmd_executed;
    wheels_cmd_executed -> lane_controller [label="feedback"];
    
    // LED control
    fsm_node -> fsm_state;
    fsm_state -> led_pattern_switch;
    led_pattern_switch -> led_pattern;
    led_pattern -> led_emitter;
    joystick_input -> led_joy_mapper;
    led_joy_mapper -> led_pattern;
    
    // State management
    fsm_state -> lane_controller;
    fsm_state -> adaptive_speed;
    fsm_state -> safety_fusion;
    
    // Monitoring
    wheels_cmd_executed -> performance_monitor;
    collision_risk -> performance_monitor;
    emergency_status -> performance_monitor;
    performance_monitor -> system_metrics;
    
    system_metrics -> system_health;
    system_health -> diagnostic_info;
    
    diagnostic_info -> data_logger;
    system_metrics -> data_logger;
    
    // Communication
    lane_pose -> v2v_communication;
    car_cmd -> v2v_communication;
    v2v_communication -> v2v_messages;
    v2v_messages -> intersection_coordinator;
    intersection_coordinator -> coordination_data;
    coordination_data -> adaptive_speed;
    
    // Visualization
    segment_list -> line_segment_visualizer;
    lane_pose -> lane_pose_visualizer;
    predicted_trajectories -> trajectory_visualizer;
    
    // AI/ML components
    object_detections -> nn_model;
    nn_model -> object_detections [label="enhanced"];
    
    object_detections -> kalman_tracker;
    kalman_tracker -> multi_object_tracker;
    multi_object_tracker -> predictive_perception;
    
    motion_models -> predictive_perception;
    
    // External interfaces
    joystick_input -> fsm_node;
    network_interface -> v2v_communication;
    file_system -> safety_config;
    safety_config -> dynamic_params;
    dynamic_params -> adaptive_speed;
    
    // Advanced features integration
    following_distance -> adaptive_speed;
    acceleration_profile -> adaptive_speed;
    environmental_analyzer -> adaptive_speed;
    
    lane_change_request -> lane_change_controller;
    lane_change_controller -> intelligent_navigation;
    intelligent_navigation -> adaptive_speed;
    
    // Cross-layer connections for advanced features
    scene_analysis -> intelligent_navigation [color="#ff6b6b", penwidth=2, label="context"];
    predicted_trajectories -> lane_change_controller [color="#4ecdc4", penwidth=2, label="prediction"];
    collision_risk -> intelligent_navigation [color="#ff6b6b", penwidth=2, label="safety"];
    
    // Performance feedback loops
    system_metrics -> dynamic_params [color="#95e1d3", style=dashed, label="optimization"];
    diagnostic_info -> safety_config [color="#95e1d3", style=dashed, label="tuning"];
}